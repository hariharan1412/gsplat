{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/ubuntu/workdir/gsplat/DATA/\"\n",
    "images_folder = os.path.join(DATA_PATH, \"images\")\n",
    "poses_file = os.path.join(DATA_PATH, \"transforms.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        images.append(np.array(img))\n",
    "    return images\n",
    "\n",
    "# Function to load poses from a JSON file\n",
    "def load_poses_from_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    poses = []\n",
    "    for frame in data['frames']:\n",
    "        poses.append(np.array(frame['transform_matrix']))\n",
    "    return poses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 929 images from /home/ubuntu/workdir/gsplat/DATA/images\n"
     ]
    }
   ],
   "source": [
    "# Load images\n",
    "images = load_images_from_folder(images_folder)\n",
    "images = np.stack([img[..., :3] for img in images])\n",
    "images = torch.from_numpy(images).float().to(device) / 255.0\n",
    "\n",
    "print(f\"Loaded {images.shape[0]} images from {images_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40592/29799323.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  c2ws = torch.tensor(poses).float().to(device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load poses\n",
    "poses = load_poses_from_file(poses_file)\n",
    "c2ws = torch.tensor(poses).float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example intrinsic matrix (K)\n",
    "K = torch.tensor([[240.0, 0.0, 240.0], [0.0, 180.0, 180.0], [0.0, 0.0, 1.0]]).to(device)  # Adjust this based on your actual camera intrinsics\n",
    "\n",
    "# Dummy data for points and colors (you should replace these with your actual data)\n",
    "points = torch.rand(5000, 3).float().to(device)\n",
    "points_rgb = torch.randint(0, 255, (5000, 3)).float().to(device)\n",
    "\n",
    "# Number of images and their dimensions\n",
    "n_images = len(images)\n",
    "height, width = images.shape[1:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
